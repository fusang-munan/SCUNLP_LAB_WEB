
@article{lei_have_2021,
	title = {Have {We} {Solved} {The} {Hard} {Problem}? {It}’s {Not} {Easy}! {Contextual} {Lexical} {Contrast} as a {Means} to {Probe} {Neural} {Coherence}},
	volume = {35},
	copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {Have {We} {Solved} {The} {Hard} {Problem}?},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/17560},
	doi = {10.1609/aaai.v35i15.17560},
	abstract = {Lexical cohesion is a fundamental mechanism for text which requires a pair of words to be interpreted as a certain type of lexical relation (e.g., similarity) to understand a coherent context; we refer to such relations as the contextual lexical relation. However, work on lexical cohesion has not modeled context comprehensively in considering lexical relations due to the lack of linguistic resources. In this paper, we take initial steps to address contextual lexical relations by focusing on the contrast relation, as it is a well-known relation though it is more subtle and relatively less resourced. We present a corpus named Cont 2 Lex to make Contextual Lexical Contrast Recognition a computationally feasible task. We benchmark this task with widely-adopted semantic representations; we discover that contextual embeddings (e.g. BERT) generally outperform static embeddings (e.g. Glove), but barely go beyond 70\% in accuracy performance. In addition, we ﬁnd that all embeddings perform better when CLC occurs within the same sentence, suggesting possible limitations of current computational coherence models. Another intriguing discovery is the improvement of BERT in CLC is largely attributed to its modeling of CLC word pairs co-occurring with other word repetitions. Such observations imply that the progress made in lexical coherence modeling remains relatively primitive even for semantic representations such as BERT that have been empowering numerous standard NLP tasks to approach human benchmarks. Through presenting our corpus and benchmark, we attempt to seed initial discussions and endeavors in advancing semantic representations from modeling syntactic and semantic levels to coherence and discourse levels.},
	language = {en},
	number = {15},
	urldate = {2025-09-16},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Lei, Wenqiang and Miao, Yisong and Xie, Runpeng and Webber, Bonnie and Liu, Meichun and Chua, Tat-Seng and Chen, Nancy F.},
	month = may,
	year = {2021},
	keywords = {Discourse, Pragmatics \& Argument Mining},
	pages = {13208--13216},
	file = {Full Text PDF:files/2/Lei 等 - 2021 - Have We Solved The Hard Problem It’s Not Easy! Contextual Lexical Contrast as a Means to Probe Neur.pdf:application/pdf},
}
